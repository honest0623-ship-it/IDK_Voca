import pandas as pd
import hashlib
import os
from datetime import datetime, timedelta
import pytz
import glob
import streamlit as st
import streamlit.components.v1 as components
from gtts import gTTS
import io
import re
import random

import calendar
# --- ì„¤ì • ë° ê²½ë¡œ ---
DB_FILE_PATTERN = 'Voca_DB_Integrated.csv'
USER_FILE = 'users.csv'

# ë“±ì—… ê¸°ì¤€
LEVEL_UP_INTERVAL_DAYS = 7
LEVEL_UP_RATIO = 0.8
LEVEL_UP_MIN_COUNT = 30

# ë ˆë²¨ ë‹¤ìš´ ê¸°ì¤€
LEVEL_DOWN_ACCURACY = 0.4

# ë ˆë²¨ ì¡°ì • ì‹¬ì‚¬ ìµœì†Œ ì¡°ê±´
MIN_TRAIN_DAYS = 3
MIN_TRAIN_COUNT = 50

# ë³´ì•ˆ ì„¤ì •
SIGNUP_SECRET_CODE = "math2026"
ADMIN_PASSWORD = "teacher1234"

# --- ë³´ì•ˆ í•¨ìˆ˜ ---
def make_hashes(password):
    return hashlib.sha256(str.encode(password)).hexdigest()

def check_hashes(password, hashed_text):
    if make_hashes(password) == hashed_text:
        return hashed_text
    return False

# --- ë‚ ì§œ/ì‹œê°„ í•¨ìˆ˜ ---
def get_korea_today():
    try:
        kst = pytz.timezone('Asia/Seoul')
        return datetime.now(kst).date()
    except Exception: return datetime.now().date()

# --- ë°ì´í„° ë¡œë”© ---
@st.cache_data(ttl=60)
def load_data():
    if os.path.exists(DB_FILE_PATTERN):
        files = [DB_FILE_PATTERN]
    else:
        files = glob.glob('Voca_DB*.csv')

    if not files: return None
    
    combined_df = pd.DataFrame()
    for filename in files:
        try:
            df = pd.read_csv(filename, encoding='utf-8-sig')
            if 'level' not in df.columns: df['level'] = 1
            if 'source' not in df.columns:
                source_name = os.path.basename(filename).replace("Voca_DB", "").replace(".csv", "").strip(" _-")
                df['source'] = source_name
            if 'root_word' in df.columns:
                df['root_word'] = df['root_word'].fillna('')
            if 'id' not in df.columns:
                df['id'] = range(1, len(df) + 1)
            if 'total_try' not in df.columns: df['total_try'] = 0
            if 'total_wrong' not in df.columns: df['total_wrong'] = 0
                
            combined_df = pd.concat([combined_df, df], ignore_index=True)
        except Exception as e:
            st.error(f"âš ï¸ {filename} ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
            continue

    if combined_df.empty: return None
    if len(files) > 1:
        combined_df = combined_df.reset_index(drop=True)
        combined_df['id'] = combined_df.index + 1
    return combined_df

def load_user_progress(username):
    filename = f"progress_{username}.csv"
    if os.path.exists(filename):
        try:
            df = pd.read_csv(filename)
            df['next_review'] = pd.to_datetime(df['next_review']).dt.date
            df['last_reviewed'] = pd.to_datetime(df['last_reviewed'], errors='coerce').dt.date
            return df
        except: pass
    return pd.DataFrame(columns=['word_id', 'last_reviewed', 'next_review', 'interval', 'fail_count'])

def save_progress(username, progress_df):
    filename = f"progress_{username}.csv"
    try:
        progress_df.to_csv(filename, index=False, encoding='utf-8-sig')
    except PermissionError:
        st.error("âš ï¸ íŒŒì¼ì„ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì—‘ì…€ íŒŒì¼ì´ ì—´ë ¤ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")

# --- í•™ìŠµ ë¡œê·¸ ---
def log_study_result(username, word_id, level, is_correct):
    log_file = f"study_log_{username}.csv"
    today = get_korea_today()
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    new_data = pd.DataFrame([{
        'timestamp': timestamp,
        'date': today,
        'word_id': word_id,
        'username': username,
        'level': level,
        'is_correct': 1 if is_correct else 0
    }])
    
    if not os.path.exists(log_file):
        new_data.to_csv(log_file, index=False, encoding='utf-8-sig')
    else:
        try:
            new_data.to_csv(log_file, mode='a', header=False, index=False, encoding='utf-8-sig')
        except: pass 

def load_study_log(username):
    log_file = f"study_log_{username}.csv"
    if os.path.exists(log_file):
        try: return pd.read_csv(log_file)
        except: pass
    return pd.DataFrame()

# --- ì‚¬ìš©ì ì •ë³´ ---
def get_user_info(username):
    if not os.path.exists(USER_FILE): return None
    users = pd.read_csv(USER_FILE)
    if username in users['username'].values:
        user_row = users[users['username'] == username].iloc[0]
        user_level = user_row['level'] if 'level' in users.columns and pd.notna(user_row['level']) else None
        real_name = user_row['name'] if 'name' in users.columns else username
        return {'level': user_level, 'name': real_name}
    return None

def update_user_level(username, new_level):
    if not os.path.exists(USER_FILE): return
    users = pd.read_csv(USER_FILE)
    if username in users['username'].values:
        idx = users[users['username'] == username].index[0]
        users.at[idx, 'level'] = new_level
        users.to_csv(USER_FILE, index=False, encoding='utf-8-sig')

# --- í…ìŠ¤íŠ¸ ìœ í‹¸ë¦¬í‹° ---
def get_masked_sentence(sentence, target_word, root_word=None):
    if not isinstance(sentence, str): return sentence
    words_to_mask = [str(target_word)]
    if root_word and isinstance(root_word, str) and root_word.strip():
        words_to_mask.append(root_word.strip())
    words_to_mask.sort(key=len, reverse=True)
    escaped_words = [re.escape(w) for w in words_to_mask]
    pattern_str = '|'.join(escaped_words)
    pattern = re.compile(pattern_str, re.IGNORECASE)
    return pattern.sub(" [ â“ ] ", sentence)

def get_highlighted_sentence(sentence, target_word):
    if not isinstance(sentence, str): return sentence
    pattern = re.compile(re.escape(target_word), re.IGNORECASE)
    replacement = r"<span style='color: #E74C3C; font-weight: 900; font-size: 1.2em;'>\g<0></span>"
    return pattern.sub(replacement, sentence)

@st.cache_data(show_spinner=False)
def text_to_speech(text):
    try:
        tts = gTTS(text=text, lang='en')
        mp3_fp = io.BytesIO()
        tts.write_to_fp(mp3_fp)
        return mp3_fp
    except Exception as e: return None

def focus_element(target_type="input"):
    components.html(
        f"""
        <div id="focus_marker_{datetime.now().timestamp()}" style="display:none;"></div>
        <script>
            function setFocus() {{
                var targetType = "{target_type}";
                var elementToFocus = null;
                if (targetType === 'input') {{
                    var inputs = window.parent.document.querySelectorAll('input[type="text"]');
                    if (inputs.length > 0) {{ elementToFocus = inputs[inputs.length - 1]; }}
                }} else if (targetType === 'button') {{
                    var buttons = window.parent.document.querySelectorAll('button[kind="primary"]');
                    if (buttons.length > 0) {{ elementToFocus = buttons[buttons.length - 1]; }}
                }}
                if (elementToFocus) {{ elementToFocus.focus(); }}
            }}
            setTimeout(setFocus, 300);
        </script>
        """,
        height=0
    )

# --- ğŸ”¥ [ì¤‘ìš”] ì´ë¦„ í†µì¼ëœ SRS ìŠ¤ì¼€ì¤„ë§ ë¡œì§ ---
# --- ğŸ” ë§ê°ê³¡ì„ (Spaced Repetition) ìŠ¤ì¼€ì¤„ ---
# - ì˜¤ë‹µ(í•œ ë²ˆì´ë¼ë„ í‹€ë¦° ë‹¨ì–´): 1ì¼ â†’ 3ì¼ â†’ 7ì¼ â†’ 14ì¼ â†’ 2ê°œì›”(â‰ˆ +2 months)
# - 'ì²˜ìŒ ì¶œì œì—ì„œ ë°”ë¡œ ì •ë‹µ' ë‹¨ì–´(ì˜¤ë‹µ ì´ë ¥ ì—†ìŒ): 2ê°œì›”(â‰ˆ +2 months)ë§ˆë‹¤
_SRS_STEPS_DAYS = [1, 3, 7, 14, 60]  # 60ì€ ì €ì¥ìš©(í†µê³„/í‘œì‹œ). ì‹¤ì œ ë‚ ì§œëŠ” ì›” ë‹¨ìœ„ë¡œ +2ê°œì›” ì²˜ë¦¬.

def _add_months(date_obj, months: int):
    """date_objì— monthsë§Œí¼ ë”í•œ ë‚ ì§œë¥¼ ë°˜í™˜(ë§ì¼ì€ ìë™ ë³´ì •)."""
    y = date_obj.year + (date_obj.month - 1 + months) // 12
    m = (date_obj.month - 1 + months) % 12 + 1
    last_day = calendar.monthrange(y, m)[1]
    d = min(date_obj.day, last_day)
    return datetime(y, m, d).date()

def update_schedule(word_id, is_correct, progress_df, today):
    # ì»¬ëŸ¼ í˜¸í™˜ (ì˜ˆì „ progress íŒŒì¼ì´ ì»¬ëŸ¼ì„ ëˆ„ë½í–ˆì„ ìˆ˜ ìˆìŒ)
    if 'fail_count' not in progress_df.columns:
        progress_df['fail_count'] = 0
    if 'last_reviewed' not in progress_df.columns:
        progress_df['last_reviewed'] = pd.NaT
    if 'next_review' not in progress_df.columns:
        progress_df['next_review'] = pd.NaT
    if 'interval' not in progress_df.columns:
        progress_df['interval'] = 0

    def _to_int(x, default=0):
        try:
            if pd.isna(x): 
                return default
        except Exception:
            pass
        try:
            return int(float(x))
        except Exception:
            return default

    def _next_step(cur_days: int):
        # cur_daysê°€ stepsì— ì—†ìœ¼ë©´, ê°€ì¥ ê°€ê¹Œìš´ í•˜ìœ„ stepìœ¼ë¡œ ë³´ì •
        if cur_days not in _SRS_STEPS_DAYS:
            cur_days = max([s for s in _SRS_STEPS_DAYS if s <= cur_days], default=1)
        if cur_days == 1: return 3
        if cur_days == 3: return 7
        if cur_days == 7: return 14
        return 60  # 14 ì´ìƒì´ë©´ ìµœì¢…(2ê°œì›”)

    if word_id in progress_df['word_id'].values:
        idx = progress_df[progress_df['word_id'] == word_id].index[0]

        # ì˜¤ëŠ˜ í•™ìŠµ ê¸°ë¡
        progress_df.loc[idx, 'last_reviewed'] = today

        cur_fail = _to_int(progress_df.loc[idx, 'fail_count'], 0)
        cur_interval = _to_int(progress_df.loc[idx, 'interval'], 0)

        if is_correct:
            # ì˜¤ë‹µ ì´ë ¥ì´ ìˆìœ¼ë©´: 1â†’3â†’7â†’14â†’2ê°œì›”
            if cur_fail > 0:
                # í˜¹ì‹œ ê³¼ê±° ë°ì´í„°ì—ì„œ interval=0ìœ¼ë¡œ ë‚¨ì•„ìˆë‹¤ë©´ 1ë¡œ ë³´ì •
                if cur_interval <= 0:
                    cur_interval = 1
                new_interval = _next_step(cur_interval)
                progress_df.loc[idx, 'interval'] = int(new_interval)

                if new_interval >= 60:
                    progress_df.loc[idx, 'next_review'] = _add_months(today, 2)
                else:
                    progress_df.loc[idx, 'next_review'] = today + timedelta(days=int(new_interval))
            else:
                # í•œ ë²ˆë„ í‹€ë¦° ì  ì—†ëŠ”(=í•œ ë²ˆì— ì •ë‹µ) ë‹¨ì–´ëŠ” 2ê°œì›” ë’¤ ì¶œì œ
                progress_df.loc[idx, 'interval'] = 60
                progress_df.loc[idx, 'next_review'] = _add_months(today, 2)

        else:
            # ì˜¤ë‹µì´ë©´: ì˜¤ë‹µë…¸íŠ¸ëŠ” 'ë‹¹ì¼'ì—ë§Œ í•˜ê³ , ë‹¤ìŒ ì¶œì œëŠ” ë¬´ì¡°ê±´ 'ë‚´ì¼(1ì¼ ë’¤)'ë¡œ
            progress_df.loc[idx, 'fail_count'] = int(cur_fail) + 1
            progress_df.loc[idx, 'interval'] = 1
            progress_df.loc[idx, 'next_review'] = today + timedelta(days=1)

    else:
        # ì‹ ê·œ ë‹¨ì–´
        if is_correct:
            new_row = {
                'word_id': word_id,
                'last_reviewed': today,
                'next_review': _add_months(today, 2),  # ì²« ì¶œì œ ì •ë‹µ â†’ 2ê°œì›” ë’¤
                'interval': 60,
                'fail_count': 0
            }
        else:
            new_row = {
                'word_id': word_id,
                'last_reviewed': today,
                'next_review': today + timedelta(days=1),  # ì˜¤ë‹µ â†’ 1ì¼ ë’¤
                'interval': 1,
                'fail_count': 1
            }
        progress_df = pd.concat([progress_df, pd.DataFrame([new_row])], ignore_index=True)

    return progress_df

# --- ğŸ”¥ [ì¤‘ìš”] ì´ë¦„ í†µì¼ëœ ë ˆë²¨ ì¡°ì • ë¡œì§ ---
def adjust_level_based_on_stats():
    log_files = glob.glob("study_log_*.csv")
    if not log_files: return 0, "í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

    all_logs = pd.DataFrame()
    for f in log_files:
        try:
            temp_df = pd.read_csv(f)
            if 'username' not in temp_df.columns:
                user_from_file = f.replace("study_log_", "").replace(".csv", "")
                temp_df['username'] = user_from_file
            all_logs = pd.concat([all_logs, temp_df], ignore_index=True)
        except: continue
    
    if all_logs.empty: return 0, "ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    if not os.path.exists(DB_FILE_PATTERN): return 0, "DB íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."

    df = pd.read_csv(DB_FILE_PATTERN, encoding='utf-8-sig')
    
    try_counts = all_logs.groupby('word_id')['username'].nunique()
    wrong_logs = all_logs[all_logs['is_correct'] == 0]
    wrong_counts = wrong_logs.groupby('word_id')['username'].nunique()
    
    updated_count = 0
    
    for word_id, user_count in try_counts.items():
        if word_id in df['id'].values:
            idx = df[df['id'] == word_id].index[0]
            wrong_user_count = wrong_counts.get(word_id, 0)
            
            df.at[idx, 'total_try'] = user_count
            df.at[idx, 'total_wrong'] = wrong_user_count
            
            wrong_rate = wrong_user_count / user_count if user_count > 0 else 0
            
            curr, new_lv = df.at[idx, 'level'], df.at[idx, 'level']
            
            # ìµœì†Œ ì¸ì› 6ëª… (í…ŒìŠ¤íŠ¸ ì‹œ 1ë¡œ ë³€ê²½)
            if user_count >= 6: 
                if wrong_rate >= 0.5: new_lv = min(30, curr + 1)
                elif wrong_rate <= 0.1: new_lv = max(1, curr - 1)
            
            if new_lv != curr:
                df.at[idx, 'level'] = new_lv
                updated_count += 1
                
    df['last_level_update'] = datetime.now().strftime("%Y-%m-%d")
    df.to_csv(DB_FILE_PATTERN, index=False, encoding='utf-8-sig')
    return updated_count, "ì„±ê³µì ìœ¼ë¡œ ì¡°ì •ë˜ì—ˆìŠµë‹ˆë‹¤."