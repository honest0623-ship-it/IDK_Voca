import pandas as pd
import hashlib
import os
import time
from datetime import datetime, timedelta
import pytz
import streamlit as st
import streamlit.components.v1 as components
from gtts import gTTS
import io
import re
import random
import calendar
import database as db

# --- 2. ê¸°ë³¸ ìƒìˆ˜ ì„¤ì • ---
LEVEL_UP_INTERVAL_DAYS = 7
LEVEL_UP_RATIO = 0.8
LEVEL_UP_MIN_COUNT = 30
LEVEL_DOWN_ACCURACY = 0.5
LEVEL_UP_ACCURACY = 0.8
MIN_TRAIN_DAYS = 0
MIN_TRAIN_COUNT = 20
SRS_STEPS_DAYS = [1, 3, 7, 14, 60, 120]

# --- Sheet read cache (TTL + write invalidation) ---
def _get_sheet_cache_ver():
    """ì„¸ì…˜ ë‹¨ìœ„ ì‹œíŠ¸ ìºì‹œ ë²„ì „ (ì“°ê¸° ì„±ê³µ ì‹œ ì¦ê°€)"""
    if '_sheet_cache_ver' not in st.session_state:
        st.session_state._sheet_cache_ver = 0
    return int(st.session_state._sheet_cache_ver)

def bump_sheet_cache_ver():
    """ì“°ê¸° í›„ ìºì‹œ ë¬´íš¨í™”ìš© ë²„ì „ ì¦ê°€"""
    st.session_state._sheet_cache_ver = _get_sheet_cache_ver() + 1

@st.cache_data(show_spinner=False, ttl=90)
def _read_sheet_to_df_cached(tab_name: str, cache_ver: int):
    """ì‹œíŠ¸ ì „ì²´ ì½ê¸° ìºì‹œ (ê¸°ë³¸ 90ì´ˆ). cache_verê°€ ë°”ë€Œë©´ ìë™ ë¬´íš¨í™”."""
    return _read_sheet_to_df_uncached(tab_name)


@st.cache_resource(show_spinner=False)
def _get_spreadsheet():
    """ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ê°ì²´ ìºì‹œ (open í˜¸ì¶œ ìµœì†Œí™”)"""
    if client is None:
        return None
    return client.open(SHEET_NAME)

# --- 3. í—¬í¼ í•¨ìˆ˜ (ì¬ì‹œë„ ë¡œì§ í¬í•¨) ---
def get_worksheet(tab_name):
    """ì›Œí¬ì‹œíŠ¸ ê°€ì ¸ì˜¤ê¸° (ì¬ì‹œë„ í¬í•¨, open í˜¸ì¶œ ìºì‹œ)"""
    sh = _get_spreadsheet()
    if sh is None:
        return None

    for attempt in range(3):  # 3ë²ˆ ì‹œë„
        try:
            return sh.worksheet(tab_name)
        except Exception as e:
            if "429" in str(e):
                time.sleep(2)
                continue
            st.error(f"ì›Œí¬ì‹œíŠ¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            return None
    return None


def _read_sheet_to_df_uncached(tab_name):
    """ë°ì´í„° ì½ê¸° (429 ì—ëŸ¬ ë°©ì§€ ë° í—¤ë” ì²˜ë¦¬ ê°•í™”)"""
    for attempt in range(3):
        try:
            ws = get_worksheet(tab_name)
            if not ws: return pd.DataFrame()

            data = ws.get_all_values()
            
            if not data or len(data) < 2:
                if data: 
                    cleaned_cols = [str(c).strip() for c in data[0]]
                    return pd.DataFrame(columns=cleaned_cols)
                return pd.DataFrame()
            
            raw_headers = data[0]
            headers = [str(h).strip() for h in raw_headers]
            
            # í—¤ë” ë¹„ìƒ ëŒ€ì±… (users íƒ­)
            if tab_name == 'users' and 'username' not in headers:
                if len(headers) >= 4:
                    headers = ['username', 'password', 'name', 'level'] + headers[4:]
            
            rows = data[1:]
            df = pd.DataFrame(rows, columns=headers)
            return df
            
        except Exception as e:
            if "429" in str(e):
                time.sleep(2)
                continue
            print(f"Sheet Load Error ({tab_name}): {e}")
            return pd.DataFrame()
    return pd.DataFrame()

def read_sheet_to_df(tab_name, use_cache: bool = True):
    """ë°ì´í„° ì½ê¸° (ê¸°ë³¸: 90ì´ˆ ìºì‹œ). ì“°ê¸° í›„ bump_sheet_cache_ver()ë¡œ ë¬´íš¨í™”."""
    if use_cache:
        return _read_sheet_to_df_cached(str(tab_name), _get_sheet_cache_ver())
    return _read_sheet_to_df_uncached(tab_name)

# --- [NEW] ì‹œìŠ¤í…œ ì„¤ì • ê´€ë¦¬ (Config) ---
@st.cache_data(ttl=60)
def get_system_config():
    """ì‹œìŠ¤í…œ ì„¤ì • ê°€ì ¸ì˜¤ê¸° (SQLite)"""
    return db.get_system_config()

def update_system_config(key, new_value):
    """ì„¤ì •ê°’ ì—…ë°ì´íŠ¸ (SQLite)"""
    if db.update_system_config(key, new_value):
        st.cache_data.clear() # ìºì‹œ ì´ˆê¸°í™”
        return True
    return False

# --- 4. ë³´ì•ˆ ë° ì‹œê°„ í•¨ìˆ˜ ---
def make_hashes(password):
    return hashlib.sha256(str.encode(password)).hexdigest()

def check_hashes(password, hashed_text):
    if make_hashes(password) == hashed_text:
        return hashed_text
    return False

def get_korea_today():
    try:
        kst = pytz.timezone('Asia/Seoul')
        return datetime.now(kst).date()
    except: return datetime.now().date()

def _add_months(date_obj, months: int):
    y = date_obj.year + (date_obj.month - 1 + months) // 12
    m = (date_obj.month - 1 + months) % 12 + 1
    last_day = calendar.monthrange(y, m)[1]
    d = min(date_obj.day, last_day)
    return datetime(y, m, d).date()

# --- 5. ë°ì´í„° ë¡œë”© ---
@st.cache_data(ttl=60)
@st.cache_data(ttl=600, show_spinner=False)
def load_data():
    """voca_db ë¡œë”© (SQLite)"""
    return db.load_all_vocab()

def load_user_progress(username):
    """ì‚¬ìš©ìì˜ í•™ìŠµ ì§„ë„ ë¡œë“œ (SQLite)"""
    return db.load_user_progress(username)

def save_progress(username, progress_df):
    """ì§„ë„ ì €ì¥ (SQLite)"""
    return db.save_user_progress(username, progress_df)

def save_progress_fast(username, progress_df):
    """ì§„ë„ ì €ì¥ (SQLite - Fast Alias)"""
    return db.save_user_progress(username, progress_df)

def save_progress_single(username, word_id, row_data):
    """ë‹¨ì¼ ë‹¨ì–´ ì§„ë„ ì €ì¥ (Optimized)
       row_data: Series or dict containing 'last_reviewed', 'next_review', 'interval', 'fail_count'
    """
    try:
        lr = row_data.get('last_reviewed')
        nr = row_data.get('next_review')
        iv = row_data.get('interval', 0)
        fc = row_data.get('fail_count', 0)
        return db.update_single_user_progress(username, word_id, lr, nr, iv, fc)
    except Exception as e:
        print(f"Wrapper Error: {e}")
        return False

def log_study_result(username, word_id, level, is_correct):
    today = get_korea_today()
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    row = [timestamp, str(today), int(word_id), username, int(level), 1 if is_correct else 0]
    db.batch_log_study_results([row])


def batch_log_study_results(rows):
    """í•™ìŠµ ë¡œê·¸ë¥¼ ì—¬ëŸ¬ í–‰ í•œ ë²ˆì— append (SQLite)"""
    return db.batch_log_study_results(rows)


def load_study_log(username):
    """ì‚¬ìš©ì í•™ìŠµ ë¡œê·¸ ë¡œë“œ (SQLite)"""
    return db.load_study_log(username)

def get_all_study_logs():
    """ëª¨ë“  í•™ìŠµ ë¡œê·¸ ë¡œë“œ (ê´€ë¦¬ììš© - SQLite)"""
    return db.get_all_study_logs()

def get_all_users():
    """ëª¨ë“  ì‚¬ìš©ì ì •ë³´ ë¡œë“œ (ê´€ë¦¬ììš© - SQLite)"""
    return db.get_all_users()

def get_user_info(username):
    """ì‚¬ìš©ì ì •ë³´ ê°€ì ¸ì˜¤ê¸° (SQLite)"""
    return db.get_user_info(username)

def manage_session_state(username, action, data):
    """
    ì§„í–‰ ì¤‘ì¸ ì„¸ì…˜(pending_session) ê´€ë¦¬
    action: 'set' (list of ids) or 'remove' (single id)
    """
    if action == 'set':
        # data expected to be list of ints or strings
        new_str = ",".join(str(x) for x in data)
        update_user_dynamic_fields(username, {'pending_session': new_str})
        
    elif action == 'remove':
        # data expected to be single id
        user_info = get_user_info(username)
        if not user_info: return
        
        current_str = user_info.get('pending_session', '')
        current_ids = [x.strip() for x in current_str.split(',') if x.strip()]
        str_id = str(data)
        
        if str_id in current_ids:
            current_ids.remove(str_id)
            new_str = ",".join(current_ids)
            update_user_dynamic_fields(username, {'pending_session': new_str})

def manage_pending_wrongs(username, action, word_id):
    """
    ì˜¤ë‹µë…¸íŠ¸(pending_wrongs) ê´€ë¦¬
    action: 'add' or 'remove'
    """
    # 1. í˜„ì¬ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
    user_info = get_user_info(username)
    if not user_info: return
    
    current_str = user_info.get('pending_wrongs', '')
    current_ids = [x.strip() for x in current_str.split(',') if x.strip()]
    
    str_id = str(word_id)
    changed = False
    
    if action == 'add':
        if str_id not in current_ids:
            current_ids.append(str_id)
            changed = True
    elif action == 'remove':
        if str_id in current_ids:
            current_ids.remove(str_id)
            changed = True
            
    if changed:
        new_str = ",".join(current_ids)
        update_user_dynamic_fields(username, {'pending_wrongs': new_str})

def update_user_dynamic_fields(username, updates):
    """ì‚¬ìš©ì ë™ì  í•„ë“œ ì—…ë°ì´íŠ¸ (SQLite)"""
    return db.update_user_dynamic_fields(username, updates)

def evaluate_level_update(current_level, correct_count, total_questions, fail_streak, level_shield, max_level=30):
    """
    "ë°©ì–´ êµ¬ê°„(Buffer) & ì—°íŒ¨ ë°©ì§€" ë¡œì§
    """
    score_percent = (correct_count / total_questions) * 100
    change = 0
    message = ""
    
    # Next state defaults
    next_streak = fail_streak
    next_shield = level_shield

    # 1. [ì´ˆê³ ì† ìŠ¹ê¸‰] 95ì  ì´ìƒ (19~20ê°œ) -> 2ë‹¨ê³„ ì í”„
    if score_percent >= 95:
        change = 2
        next_streak = 0
        next_shield = 3 # ìƒˆ ë ˆë²¨ ì‰´ë“œ ì¶©ì „
        message = "ì™„ë²½í•´ìš”! ì‹¤ë ¥ì´ ì••ë„ì ì´ë¼ 2ë‹¨ê³„ ìŠ¹ê¸‰í•©ë‹ˆë‹¤! ğŸš€"

    # 2. [ìŠ¹ê¸‰] 80ì  ì´ìƒ (16~18ê°œ) -> 1ë‹¨ê³„ ìƒìŠ¹
    elif score_percent >= 80:
        change = 1
        next_streak = 0
        next_shield = 3 # ìƒˆ ë ˆë²¨ ì‰´ë“œ ì¶©ì „
        message = "ì°¸ ì˜í–ˆì–´ìš”! ë‹¤ìŒ ë ˆë²¨ë¡œ ì˜¬ë¼ê°‘ë‹ˆë‹¤. ğŸ‰"

    # 3. [ìœ ì§€] 60ì  ~ 79ì  (12~15ê°œ) -> í˜„ìƒ ìœ ì§€
    elif score_percent >= 60:
        change = 0
        next_streak = 0 # ì¤‘ê°„ë§Œ ê°€ë„ ê²½ê³  ì´ˆê¸°í™”
        # ì‰´ë“œ ì°¨ê°
        if next_shield > 0:
            next_shield -= 1
        message = "ìˆ˜ê³ í–ˆì–´ìš”. í˜„ì¬ ë ˆë²¨ì„ ìœ ì§€í•˜ë©° ì‹¤ë ¥ì„ ë‹¤ì ¸ë´…ì‹œë‹¤."

    # 4. [í•˜í–¥ ìœ„ê¸°] 60ì  ë¯¸ë§Œ (11ê°œ ì´í•˜)
    else:
        change = 0
        # A. ì‰´ë“œ í™•ì¸
        if next_shield > 0:
            next_shield -= 1
            message = f"ì•„ì§ ì ì‘ ê¸°ê°„ì´ì—ìš”. ê´œì°®ìŠµë‹ˆë‹¤! (ë‚¨ì€ ë³´í˜¸ íšŸìˆ˜: {next_shield})"
        else:
            # B. ì—°íŒ¨ ì²´í¬
            next_streak += 1
            if next_streak >= 2:
                change = -1
                next_streak = 0
                next_shield = 3 # ë ˆë²¨ ë‚´ë ¤ê°€ë©´ ë‹¤ì‹œ ì ì‘ ê¸°íšŒ ë¶€ì—¬
                message = "ë„ˆë¬´ ì–´ë ¤ì› ë‚˜ìš”? í•œ ë‹¨ê³„ ë‚®ì¶°ì„œ ê¸°ì´ˆë¥¼ ë³µìŠµí•´ë´ìš”. â¬‡ï¸"
            else:
                message = "âš  ì£¼ì˜! ë‹¤ìŒì—ë„ ì ìˆ˜ê°€ ë‚®ìœ¼ë©´ ë ˆë²¨ì´ ë‚´ë ¤ê°ˆ ìˆ˜ ìˆì–´ìš”."

    new_level = current_level + change
    new_level = max(1, min(new_level, max_level))
    
    return new_level, next_streak, next_shield, message

def register_user(username, password, name):
    """ì‚¬ìš©ì ë“±ë¡ (SQLite)"""
    hashed_pw = make_hashes(password)
    return db.register_user(username, hashed_pw, name)

def update_user_level(username, new_level):
    """ì‚¬ìš©ì ë ˆë²¨ ì—…ë°ì´íŠ¸ (SQLite)"""
    db.update_user_level(username, new_level)


def reset_user_password(username, new_password):
    """ë¹„ë°€ë²ˆí˜¸ ì´ˆê¸°í™” (SQLite)"""
    hashed_pw = make_hashes(new_password)
    return db.reset_user_password(username, hashed_pw)

def update_schedule(word_id, is_correct, progress_df, today):
    # ì»¬ëŸ¼ ë³´ì •
    for col in ['fail_count', 'interval']:
        if col not in progress_df.columns:
            progress_df[col] = 0
    for col in ['last_reviewed', 'next_review']:
        if col not in progress_df.columns:
            progress_df[col] = pd.NaT

    def _to_int(x, default=0):
        try:
            return int(float(x)) if pd.notna(x) and str(x).strip() != "" else default
        except:
            return default

    def _next_step(cur_days):
        # ì˜¤ë‹µ ê²½í—˜ ë‹¨ì–´: 1 â†’ 3 â†’ 7 â†’ 14 â†’ 60(2ê°œì›”) â†’ 120(4ê°œì›”)
        if cur_days == 1: return 3
        if cur_days == 3: return 7
        if cur_days == 7: return 14
        if cur_days == 14: return 60
        if cur_days == 60: return 120
        return 120

    def _calc_next_review(base_date, interval_days: int):
        if interval_days >= 240: # 8ê°œì›” ì´ìƒ
            return _add_months(base_date, 8)
        if interval_days >= 120:
            return _add_months(base_date, 4)
        if interval_days >= 60:
            return _add_months(base_date, 2)
        return base_date + timedelta(days=int(interval_days))

    JUMP_INTERVAL = 240 # 8ê°œì›” (ì•½ 240ì¼)
    RETIRE_DATE = datetime(9999, 12, 31).date()

    if 'word_id' in progress_df.columns and word_id in progress_df['word_id'].values:
        idx = progress_df[progress_df['word_id'] == word_id].index[0]
        
        # ì´ì „ ê¸°ë¡ ê°€ì ¸ì˜¤ê¸° (ì—…ë°ì´íŠ¸ ì „)
        prev_last_reviewed = progress_df.loc[idx, 'last_reviewed']
        # [ë°©ì–´ ë¡œì§] í˜¹ì‹œ ë¬¸ìì—´ì´ë©´ ë‚ ì§œ ê°ì²´ë¡œ ë³€í™˜
        if isinstance(prev_last_reviewed, str):
            prev_last_reviewed = pd.to_datetime(prev_last_reviewed, errors='coerce').date()
            
        cur_interval = _to_int(progress_df.loc[idx, 'interval'], 0)
        
        progress_df.loc[idx, 'last_reviewed'] = today
        cur_fail = _to_int(progress_df.loc[idx, 'fail_count'], 0)

        if is_correct:
            # 1. ì€í‡´(ì¡¸ì—…) ì²´í¬: ì´ë¯¸ 8ê°œì›”(240ì¼) ê°„ê²©ì´ì—ˆë˜ ë‹¨ì–´ë¥¼ ë§ì¶¤ -> ì˜êµ¬ ì¡¸ì—…
            if cur_interval >= JUMP_INTERVAL:
                progress_df.loc[idx, 'next_review'] = RETIRE_DATE
                # intervalì€ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ê±°ë‚˜ ì¡¸ì—… ì½”ë“œ ë¶€ì—¬ (ì—¬ê¸°ì„  ìœ ì§€)
            else:
                # 2. 8ê°œì›” ì í”„ ì²´í¬: ë§ˆì§€ë§‰ ë¦¬ë·°ë¡œë¶€í„° 30ì¼ ì´ìƒ ì§€ë‚¬ëŠ”ë° í•œ ë²ˆì— ë§ì¶¤
                days_since = (today - prev_last_reviewed).days if pd.notna(prev_last_reviewed) else 0
                
                if days_since >= 30:
                    progress_df.loc[idx, 'interval'] = JUMP_INTERVAL
                    progress_df.loc[idx, 'next_review'] = _add_months(today, 8)
                else:
                    # 3. ì¼ë°˜ SRS ë¡œì§
                    if cur_fail > 0:
                        if cur_interval <= 0:
                            cur_interval = 1
                        new_interval = _next_step(cur_interval)
                        progress_df.loc[idx, 'interval'] = int(new_interval)
                        progress_df.loc[idx, 'next_review'] = _calc_next_review(today, int(new_interval))
                    else:
                        # ì˜¤ë‹µ ê²½í—˜ ì—†ëŠ” ë‹¨ì–´ (30ì¼ ì´ë‚´ ì¬í•™ìŠµ): ê¸°ì¡´ ë¡œì§ ìœ ì§€ (2ê°œì›”)
                        # í˜¹ì‹œ intervalì´ ë„ˆë¬´ ì§§ë‹¤ë©´ ì¡°ì • ê°€ëŠ¥í•˜ë‚˜, ê¸°ì¡´ ë¡œì§ ë”°ë¦„
                        progress_df.loc[idx, 'interval'] = 60
                        progress_df.loc[idx, 'next_review'] = _add_months(today, 2)
        else:
            progress_df.loc[idx, 'fail_count'] = int(cur_fail) + 1
            progress_df.loc[idx, 'interval'] = 1
            progress_df.loc[idx, 'next_review'] = today + timedelta(days=1)

    else:
        # ì‹ ê·œ ë‹¨ì–´
        if is_correct:
            # ì²˜ìŒ ì¶œì œëœ ë¬¸ì œë¥¼ í•œ ë²ˆì— ë§ì¶¤ -> 8ê°œì›” ë’¤ ì¶œì œ
            new_row = {
                'word_id': int(word_id),
                'last_reviewed': today,
                'interval': JUMP_INTERVAL,
                'fail_count': 0,
                'next_review': _add_months(today, 8)
            }
        else:
            # í‹€ë¦¼ -> 1ì¼ ë’¤
            new_row = {
                'word_id': int(word_id),
                'last_reviewed': today,
                'interval': 1,
                'fail_count': 1,
                'next_review': today + timedelta(days=1)
            }
        progress_df = pd.concat([progress_df, pd.DataFrame([new_row])], ignore_index=True)

    # íƒ€ì… ì •ë¦¬ (ì•ˆì „)
    if 'word_id' in progress_df.columns:
        progress_df['word_id'] = pd.to_numeric(progress_df['word_id'], errors='coerce').fillna(0).astype(int)
    if 'interval' in progress_df.columns:
        progress_df['interval'] = pd.to_numeric(progress_df['interval'], errors='coerce').fillna(0).astype(int)
    if 'fail_count' in progress_df.columns:
        progress_df['fail_count'] = pd.to_numeric(progress_df['fail_count'], errors='coerce').fillna(0).astype(int)

    return progress_df

# --- 9. ê¸°íƒ€ ìœ í‹¸ ---
def get_random_question(level, exclude_ids=[]):
    """ì§€ì •ëœ ë ˆë²¨ì˜ ëœë¤ ë¬¸ì œ 1ê°œ ë°˜í™˜ (ì—†ìœ¼ë©´ ê·¼ì ‘ ë ˆë²¨ íƒìƒ‰)"""
    df = load_data()
    if df is None or df.empty:
        return None
    
    # 1. í•´ë‹¹ ë ˆë²¨ì˜ ë‹¨ì–´ í•„í„°ë§ (exclude_ids ì œì™¸)
    base_pool = df
    if exclude_ids:
        base_pool = df[~df['id'].isin(exclude_ids)]
        if base_pool.empty: base_pool = df # ì œì™¸ í›„ ì—†ìœ¼ë©´ ì „ì²´ì—ì„œ (ì¤‘ë³µ í—ˆìš©)

    candidates = base_pool[base_pool['level'] == level]
    
    # 2. í•´ë‹¹ ë ˆë²¨ì— ë‹¨ì–´ê°€ ì—†ìœ¼ë©´ -> ê°€ì¥ ê°€ê¹Œìš´ ë ˆë²¨ ì°¾ê¸°
    if candidates.empty:
        available_levels = base_pool['level'].unique()
        if len(available_levels) > 0:
            # í˜„ì¬ levelê³¼ ì°¨ì´ê°€ ê°€ì¥ ì ì€ ë ˆë²¨ ì°¾ê¸°
            nearest_level = min(available_levels, key=lambda x: abs(x - level))
            candidates = base_pool[base_pool['level'] == nearest_level]
        else:
            candidates = base_pool # ì •ë§ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°

    if candidates.empty:
        return None
    
    # [FIX] í’ˆì§ˆ ê°œì„ : "The word '...' is important." ê°™ì€ ë”ë¯¸ ë¬¸ì¥ ì œì™¸ ìš°ì„ ìˆœìœ„ ì ìš©
    # ì •ê·œì‹ìœ¼ë¡œ ë”ë¯¸ íŒ¨í„´ í™•ì¸ (The word '...' is important.)
    dummy_pattern = r"^The word '.*' is important\.$"
    good_candidates = candidates[~candidates['sentence_en'].str.contains(dummy_pattern, regex=True, na=False)]
    
    if not good_candidates.empty:
        return good_candidates.sample(n=1).iloc[0].to_dict()
        
    return candidates.sample(n=1).iloc[0].to_dict()

def text_to_speech(word_id, text):
    """
    1) í…ìŠ¤íŠ¸ í•´ì‹œ ê¸°ë°˜ íŒŒì¼ëª… í™•ì¸: tts_audio/{word_id}_{hash}.mp3
    2) ìˆìœ¼ë©´ ë°˜í™˜
    3) ì—†ìœ¼ë©´:
       - ê¸°ì¡´ í•´ë‹¹ word_idì˜ êµ¬ë²„ì „/ë‹¤ë¥¸ í•´ì‹œ íŒŒì¼ ì‚­ì œ (ì²­ì†Œ)
       - gTTS ìƒì„± í›„ ì €ì¥
       - ë°˜í™˜
    """
    # í´ë” í™•ë³´
    if not os.path.exists("tts_audio"):
        try:
            os.makedirs("tts_audio")
        except: pass
        
    # í…ìŠ¤íŠ¸ í•´ì‹œ ìƒì„± (ë‚´ìš© ë³€ê²½ ê°ì§€ìš©)
    text_hash = hashlib.md5(text.encode('utf-8')).hexdigest()[:8]
    filename = f"{word_id}_{text_hash}.mp3"
    file_path = f"tts_audio/{filename}"
    
    # 1. í˜„ì¬ í…ìŠ¤íŠ¸ì™€ ì¼ì¹˜í•˜ëŠ” ìºì‹œ íŒŒì¼ì´ ìˆìœ¼ë©´ ë°˜í™˜
    if os.path.exists(file_path):
        try:
            with open(file_path, "rb") as f:
                return f.read()
        except:
            pass

    # 2. ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±í•´ì•¼ í•¨. ê·¸ ì „ì— êµ¬ë²„ì „ íŒŒì¼ ì²­ì†Œ
    # (ì˜ˆ: 101.mp3 ë˜ëŠ” 101_oldhash.mp3)
    try:
        for f in os.listdir("tts_audio"):
            # í•´ë‹¹ IDë¡œ ì‹œì‘í•˜ëŠ” íŒŒì¼ ì°¾ê¸°
            if f.startswith(f"{word_id}.") or f.startswith(f"{word_id}_"):
                # í˜„ì¬ í•„ìš”í•œ íŒŒì¼ì´ ì•„ë‹ˆë©´ ì‚­ì œ
                if f != filename:
                    try:
                        os.remove(os.path.join("tts_audio", f))
                    except:
                        pass
    except:
        pass

    # 3. gTTSë¡œ ìƒì„± í›„ ì €ì¥
    try:
        tts = gTTS(text=text, lang='en')
        tts.save(file_path)
        with open(file_path, "rb") as f:
            return f.read()
    except:
        return None

def get_masked_sentence(sentence, target_word, root_word=None):
    if not isinstance(sentence, str): return sentence
    words_to_mask = [str(target_word)]
    if root_word and isinstance(root_word, str) and root_word.strip():
        words_to_mask.append(root_word.strip())
    words_to_mask.sort(key=len, reverse=True)
    escaped_words = [re.escape(w) for w in words_to_mask]
    pattern_str = '|'.join(escaped_words)
    pattern = re.compile(pattern_str, re.IGNORECASE)
    return pattern.sub(" [ â“ ] ", sentence)

def get_highlighted_sentence(sentence, target_word):
    if not isinstance(sentence, str): return sentence
    pattern = re.compile(re.escape(target_word), re.IGNORECASE)
    return pattern.sub(r"<span style='color: #E74C3C; font-weight: 900; font-size: 1.2em;'>\g<0></span>", sentence)

def focus_element(target_type="input"):
    """
    JSë¥¼ ì´ìš©í•´ ì§€ì •ëœ ìš”ì†Œ(input ë˜ëŠ” button)ì— í¬ì»¤ìŠ¤ë¥¼ ê°•ì œë¡œ ìœ„ì¹˜ì‹œí‚´.
    """
    components.html(
        f"""
        <script>
            try {{
                setTimeout(function() {{
                    var targets = window.parent.document.querySelectorAll('{ "input[type=text]" if target_type == "input" else "button" }');
                    if (targets.length > 0) {{
                        // ê°€ì¥ ë§ˆì§€ë§‰ ìš”ì†Œì— í¬ì»¤ìŠ¤ (ë³´í†µ í˜„ì¬ í™œì„±í™”ëœ ì»´í¬ë„ŒíŠ¸)
                        targets[targets.length - 1].focus();
                    }}
                }}, 300);
            }} catch(e) {{
                console.log("Focus Error: " + e);
            }}
        </script>
        """,
        height=0
    ) 


def adjust_level_based_on_stats():
    """
    ë‹¨ì–´ ë‚œì´ë„ ìë™ ì¡°ì • (Weighted Gap Algorithm)
    - í•™ìƒ ë ˆë²¨ê³¼ ë‹¨ì–´ ë ˆë²¨ì˜ ì°¨ì´ë¥¼ ê°€ì¤‘ì¹˜ë¡œ ì‚¬ìš©
    - ê³ ë ˆë²¨ í•™ìƒì´ í‹€ë¦¬ë©´ ë‹¨ì–´ ë ˆë²¨ ìƒìŠ¹ (ê°•ë ¥)
    - ì €ë ˆë²¨ í•™ìƒì´ ë§ì¶”ë©´ ë‹¨ì–´ ë ˆë²¨ í•˜ë½ (ê°•ë ¥)
    """
    try:
        logs_df = get_all_study_logs()
        words_df = load_data()
        
        if logs_df.empty or words_df is None:
            return 0, "ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."

        # ë‹¨ì–´ë³„ í˜„ì¬ ë ˆë²¨ ë§¤í•‘
        word_levels = dict(zip(words_df['id'], words_df['level']))
        
        # ì¡°ì • ì ìˆ˜ ê³„ì‚°
        adjustment_scores = {} # word_id -> score
        
        # ë¡œê·¸ ë¶„ì„ (ìµœê·¼ 1000ê±´ ì •ë„ë§Œ? ì•„ë‹ˆë©´ ì „ì²´? ì¼ë‹¨ ì „ì²´ í•˜ë˜ ë°ì´í„° ë§ìœ¼ë©´ ìµœì í™” í•„ìš”)
        # ì—¬ê¸°ì„  ì „ì²´ ë¶„ì„
        for _, row in logs_df.iterrows():
            word_id = row['word_id']
            user_lv = row['level'] # ë¡œê·¸ ë‹¹ì‹œ ìœ ì € ë ˆë²¨ (ì´ê±¸ ì¨ì•¼ ì •í™•í•¨. í˜„ì¬ ìœ ì € ë ˆë²¨ë³´ë‹¤ ê¸°ë¡ ë‹¹ì‹œ ìƒí™©ì´ ì¤‘ìš”)
            is_correct = row['is_correct']
            
            if word_id not in word_levels: continue
            
            cur_word_lv = word_levels[word_id]
            gap = user_lv - cur_word_lv
            
            score = 0
            if is_correct:
                if gap < 0: # ì €ë ˆë²¨ í•™ìƒì´ ë§ì¶¤ (ì‰¬ì›€)
                    score = -abs(gap) * 2.0
                elif gap == 0:
                    score = -0.5
                # gap > 0 (ê³ ë ˆë²¨ì´ ë§ì¶¤) -> ë‹¹ì—°í•¨ (ë³€ë™ ì—†ìŒ)
            else:
                if gap > 0: # ê³ ë ˆë²¨ í•™ìƒì´ í‹€ë¦¼ (ì–´ë ¤ì›€)
                    score = abs(gap) * 2.0
                elif gap == 0:
                    score = 0.5
                # gap < 0 (ì €ë ˆë²¨ì´ í‹€ë¦¼) -> ë‹¹ì—°í•¨ (ë³€ë™ ì—†ìŒ)
                
            adjustment_scores[word_id] = adjustment_scores.get(word_id, 0) + score

        # ë³€ê²½ ëŒ€ìƒ ì„ ë³„ (Threshold: +/- 15ì )
        THRESHOLD = 15
        updates = []
        
        for word_id, score in adjustment_scores.items():
            current_lv = word_levels[word_id]
            new_lv = current_lv
            
            if score >= THRESHOLD:
                new_lv += 1
            elif score <= -THRESHOLD:
                new_lv -= 1
                
            # ë²”ìœ„ ì œí•œ (1~30)
            new_lv = max(1, min(30, new_lv))
            
            if new_lv != current_lv:
                updates.append((new_lv, word_id))
        
        # DB ì—…ë°ì´íŠ¸
        if updates:
            if db.batch_update_vocab_levels(updates):
                st.cache_data.clear() # ë°ì´í„° ê°±ì‹ 
                return len(updates), f"{len(updates)}ê°œ ë‹¨ì–´ì˜ ë‚œì´ë„ê°€ ì¬ì¡°ì •ë˜ì—ˆìŠµë‹ˆë‹¤."
            else:
                return 0, "DB ì—…ë°ì´íŠ¸ ì‹¤íŒ¨"
                
        return 0, "ì¡°ì • ëŒ€ìƒì´ ì—†ìŠµë‹ˆë‹¤."

    except Exception as e:
        print(f"Level Adjust Error: {e}")
        return 0, f"ì˜¤ë¥˜ ë°œìƒ: {e}"

def update_student_info(old_username, new_username, new_name, new_level):
    """í•™ìƒ ì •ë³´ ìˆ˜ì • (ID, ì´ë¦„, ë ˆë²¨) - SQLite"""
    return db.update_student_info(old_username, new_username, new_name, new_level)

def delete_student(username):
    """í•™ìƒ ì‚­ì œ (ê´€ë ¨ ê¸°ë¡ Cascade ì‚­ì œ)"""
    return db.delete_student(username)

def add_word(target_word, meaning, level, sentence_en, sentence_ko, root_word):
    """ë‹¨ì–´ ì¶”ê°€"""
    return db.add_word(target_word, meaning, level, sentence_en, sentence_ko, root_word)

def update_word(word_id, target_word, meaning, level, sentence_en, sentence_ko, root_word):
    """ë‹¨ì–´ ìˆ˜ì •"""
    return db.update_word(word_id, target_word, meaning, level, sentence_en, sentence_ko, root_word)

def delete_word(word_id):
    """ë‹¨ì–´ ì‚­ì œ"""
    return db.delete_word(word_id)

def process_excel_upload(file):
    """ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬"""
    try:
        df = pd.read_excel(file)
        # ì»¬ëŸ¼ ì´ë¦„ ê³µë°± ì œê±°
        df.columns = [str(c).strip() for c in df.columns]
        
        if 'target_word' not in df.columns or 'meaning' not in df.columns:
            return False, "ì—‘ì…€ íŒŒì¼ì— 'target_word'ì™€ 'meaning' ì»¬ëŸ¼ì´ ë°˜ë“œì‹œ ìˆì–´ì•¼ í•©ë‹ˆë‹¤."
            
        added, updated = db.bulk_upsert_words(df)
        return True, f"âœ… ì²˜ë¦¬ ì™„ë£Œ: {added}ê°œ ì¶”ê°€, {updated}ê°œ ìˆ˜ì •ë¨"
    except Exception as e:
        return False, f"ì˜¤ë¥˜ ë°œìƒ: {e}"